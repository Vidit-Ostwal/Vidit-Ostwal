# Recent GitHub Activity for Vidit-Ostwal

## üìù Recent Blogs
- [Training the Tokenizer](https://www.notion.so/207e478805d48090b34fcc5c8e8c3c01?v=207e478805d480cfac6c000ca3c80482) - *03-06-2025*
- [Self-Attention in Transformers](https://www.notion.so/viditostwal/Self-Attention-in-Transformers-216e478805d48005b515fac90e1d76e0) - *21-06-2025*
## üí¨ Recent Comments
- [Commented](https://github.com/crewAIInc/crewAI/issues/3028#issuecomment-2988939248) in [crewAIInc/crewAI] on 2025-06-19.
  > *AI Summary: @Vidit-Ostwal has suggested the concept of utilizing Docker inside Docker for enhanced container management. This approach allows developers to create and manage Docker containers within a containerized environment, facilitating testing and isolation. It can be particularly beneficial for continuous integration and deployment pipelines, enabling seamless integration of containerized applications. However, careful consideration should be given to security implications, resource management, and performance overhead associated with this technique. Proper configurations and best practices are essential to ensure efficient Docker operation within another Docker instance.*
- [Commented](https://github.com/ariG23498/gemma3-object-detection/issues/35#issuecomment-2988787234) in [ariG23498/gemma3-object-detection] on 2025-06-19.
  > *AI Summary: @Vidit-Ostwal has suggested exploring the absence of chat templates in the current implementation. It is essential to understand the rationale behind their exclusion, as chat templates could potentially enhance functionality or streamline communication. Analyzing this decision may provide insights into design choices and guide future improvements. Clarifying this aspect could lead to better user experience and address any gaps in current methodology. Overall, understanding the choice not to utilize chat templates warrants further discussion and consideration.*
- [Commented](https://github.com/ariG23498/gemma3-object-detection/issues/35#issuecomment-2988765222) in [ariG23498/gemma3-object-detection] on 2025-06-19.
  > *AI Summary: @Vidit-Ostwal has suggested uncertainty regarding the impact of not masking a specific token. They are seeking guidance on the significance of this omission and how it might affect the overall results. The inquiry reflects a desire for clarification on the importance of full masking in their context and whether missing this step could have notable implications. They aim to understand better the potential consequences of their current approach and any additional considerations they should take into account.*
- [Commented](https://github.com/ariG23498/gemma3-object-detection/pull/29#issuecomment-2988518712) in [ariG23498/gemma3-object-detection] on 2025-06-19.
  > *AI Summary: @Vidit-Ostwal has suggested appreciation for the implementation and expressed intent to merge it for quicker internal iterations. Additionally, there was a query regarding the implementation of adding a flag to call a training route, but it was confirmed that this idea is already included in the latest addition. The exchange also reflects a light-hearted apology for being misinformed about the existing features. Overall, the focus is on enhancing collaboration and ensuring efficient project development.*
- [Commented](https://github.com/ariG23498/gemma3-object-detection/pull/34#issuecomment-2988517525) in [ariG23498/gemma3-object-detection] on 2025-06-19.
  > *AI Summary: @Vidit-Ostwal has suggested that the observed plateauing of the loss curves indicates that the current method utilized may not be adequate for effective results. This observation highlights the potential necessity for employing a more advanced technique to improve outcomes. Additionally, @Vidit-Ostwal poses a question regarding possible approaches to enhance the current methodology, inviting discussion on alternative strategies that could lead to better performance in the task at hand.*

## üêõ Issues Raised
- Raised an [issue](https://github.com/ariG23498/gemma3-object-detection/issues/35) in [ariG23498/gemma3-object-detection]: `bos_token` used to mask instead of `boi_token` (2025-06-19).
  > *AI Summary: @Vidit-Ostwal has suggested a review of the data loader's functionality and the exact inputs fed into the model. Notably, when the model ID is set to 'google/gemma-3-4b-pt', it appears that `boi_token` should be utilized to accurately identify the `image_token_id` instead of `bos_token`. This observation aligns with the guidance found on the official Gemma3 documentation about fine-tuning with Qlora, which also recommends the use of `boi_token`. Proper adherence to these tokens is crucial for successful model training and data processing.*
- Raised an [issue](https://github.com/ishandutta0098/mukh/issues/21) in [ishandutta0098/mukh]: Roadmap for future development (2025-06-18).
  > *AI Summary: @Vidit-Ostwal has suggested appreciation for the new open-source project. They are inquiring about a future roadmap for feature development to understand planned enhancements. Additionally, they have expressed interest in collaborating and contributing to the project, indicating a willingness to engage actively and support its growth through contributions. This highlights the importance of community involvement in open-source initiatives and the potential for collaborative efforts that can enhance the project's success and innovation.*

## üöÄ Pull Requests
- Opened a [PR](https://github.com/ishandutta0098/mukh/pull/26) in [ishandutta0098/mukh]: Output now is saved in .json rather than .json (2025-06-19).
  > *AI Summary: @Vidit-Ostwal has suggested fixing the issue indicated in the problem statement. The proposed solution addresses the specific concerns outlined in the ticket while ensuring that it adheres to the project's guidelines. By implementing this fix, the aim is to resolve the reported bugs effectively. This will enhance the overall functionality and user experience. The implementation should be tested thoroughly to ensure all aspects are functioning as intended and no new issues are introduced in the process.*
- Opened a [PR](https://github.com/ariG23498/gemma3-object-detection/pull/36) in [ariG23498/gemma3-object-detection]: fixed masking token (2025-06-19).
  > *AI Summary: @Vidit-Ostwal has suggested that the issue labeled as #35 has been successfully addressed. The proposed changes have resolved the underlying problem, ensuring the functionality is now working as intended. This fix contributes to the overall improvement of the project, enhancing user experience and performance. By tackling this issue, vital progress has been made, leading to a more polished and reliable product. The focus remains on continuous improvement and ensuring that all reported issues are efficiently resolved.*
- Opened a [PR](https://github.com/crewAIInc/crewAI/pull/3021) in [crewAIInc/crewAI]: Fixed type annotation in task (2025-06-17).
  > *AI Summary: @Vidit-Ostwal has suggested addressing issue number 3020. The comment implies the need for a solution or improvement related to the specified problem. Acknowledging and fixing reported issues is essential for maintaining project integrity and functionality. The comment indicates readiness to implement necessary changes to resolve this issue effectively, emphasizing proactive contribution to the project. By addressing this matter, it will likely enhance the overall quality and user experience of the application, aligning with community expectations and standards.*
- Opened a [PR](https://github.com/ariG23498/gemma3-object-detection/pull/32) in [ariG23498/gemma3-object-detection]: Added functionality to measure VRAM (2025-06-16).
  > *AI Summary: @Vidit-Ostwal has suggested the addition of the `measure_vram.py` file, which separates the model initialization into a distinct function. This organization allows for easier modifications, enabling users to adjust the configuration as needed, whether they are attempting fine-tuning with different settings, LORA, or full fine-tuning. By implementing this change, users can have greater flexibility in their fine-tuning processes, facilitating experimentation with various model configurations without altering the entire codebase.*

## ‚≠ê Starred Repositories
- Starred [huggingface/smolagents](https://github.com/huggingface/smolagents) on 2025-06-20.
- Starred [ishandutta0098/mukh](https://github.com/ishandutta0098/mukh) on 2025-06-19.
- Starred [Shubhamsaboo/awesome-llm-apps](https://github.com/Shubhamsaboo/awesome-llm-apps) on 2025-06-16.
- Starred [huggingface/trl](https://github.com/huggingface/trl) on 2025-06-16.

## üç¥ Forked Repositories
- Forked [ishandutta0098/mukh](https://github.com/Vidit-Ostwal/mukh) on 2025-06-19.
