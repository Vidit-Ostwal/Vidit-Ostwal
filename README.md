# Recent GitHub Activity for Vidit-Ostwal

## üìù Recent Blogs
- [Training the Tokenizer](https://www.notion.so/207e478805d48090b34fcc5c8e8c3c01?v=207e478805d480cfac6c000ca3c80482) - *03-06-2025*
- [Self-Attention in Transformers](https://www.notion.so/viditostwal/Self-Attention-in-Transformers-216e478805d48005b515fac90e1d76e0) - *21-06-2025*
  - [Masked Self-Attention](https://www.notion.so/viditostwal/Self-Attention-in-Transformers-216e478805d48005b515fac90e1d76e0) - *25-06-2025*
- [Temperature in LLM](https://open.substack.com/pub/viditostwal/p/how-does-temperature-changes-the?r=m52qu&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false) - *10-07-2025*
- [KV Caching in Transformers](https://open.substack.com/pub/viditostwal/p/kv-key-value-cache-in-transformers?r=m52qu&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false) - *26-07-2025*
## üí¨ Recent Comments
- [Commented](https://github.com/crewAIInc/crewAI/pull/3390#issuecomment-3217132293) in [crewAIInc/crewAI] on 2025-08-23.
  > *AI Summary: @Vidit-Ostwal has suggested that the issue regarding the designated problem, identified as #3391, has been addressed and resolved. They implied that the changes implemented effectively tackle the complications outlined in the issue report. This resolution signifies a pivotal step in improving the overall functionality or performance related to the discussed topic. By addressing these concerns, they indicate progress is being made within the project, reinforcing the commitment to quality and efficiency in the ongoing development process.*
- [Commented](https://github.com/crewAIInc/crewAI/issues/3185#issuecomment-3216682728) in [crewAIInc/crewAI] on 2025-08-23.
  > *AI Summary: @Vidit-Ostwal has suggested an observation regarding the code, noting the absence of scenarios where CrewOutput is instantiated without task_outputs. They emphasize the importance of confirming this observation with a maintainer for validation. This highlights the necessity of collaboration and verification in the coding process to ensure accuracy and reliability in implementations. The comment reflects an understanding of responsible coding practices while also seeking additional insight from a more experienced team member.*
- [Commented](https://github.com/crewAIInc/crewAI/issues/3185#issuecomment-3216270555) in [crewAIInc/crewAI] on 2025-08-23.
  > *AI Summary: @Vidit-Ostwal has suggested that it might be reasonable to skip a particular test case, as instantiating CrewOutput without task_outputs is unlikely to occur. Additionally, there is confusion regarding the differing requirements for creating CrewOutput instances directly versus through the kickoff method. It is proposed that error handling for the absence of TaskOutput could be improved by implementing checks within the CrewOutput class itself, rather than handling these scenarios externally, thereby ensuring better robustness and clarity in its functionality.*
- [Commented](https://github.com/crewAIInc/crewAI/issues/2885#issuecomment-3216179723) in [crewAIInc/crewAI] on 2025-08-23.
  > *AI Summary: @Vidit-Ostwal has suggested trying to debug the issue and has requested the project file along with the implementation details of the tools used. This information will help in understanding the context better and facilitate the debugging process effectively. Sharing these files is crucial for identifying any underlying problems and ensuring that a resolution can be reached promptly. Collaboration on this matter is essential for a successful outcome in addressing the issue at hand.*
- [Commented](https://github.com/crewAIInc/crewAI/issues/3169#issuecomment-3214365725) in [crewAIInc/crewAI] on 2025-08-22.
  > *AI Summary: @Vidit-Ostwal has suggested saving a unique file in the project while inquiring about the relevant embedder. The comment indicates that knowledge sources may be chunked and retrieved, mentioning that the default models require an OpenAI key. However, it points out that a different model is being utilized, asking either for the OpenAI key to be provided or for the relevant embedder function to be set up within the project.*

## üêõ Issues Raised
- Raised an [issue](https://github.com/crewAIInc/crewAI/issues/3391) in [crewAIInc/crewAI]: [BUG] Mem0 Storage metadata limit breach (2025-08-23).
  > *AI Summary: @Vidit-Ostwal has suggested that when using External Memory with Mem0, save requests fail if metadata exceeds 2000 characters, due to the inclusion of assistant messages, user messages, and system prompts. The expected functionality should allow processing beyond this character limit without issues. The problem can be reproduced by generating a response that surpasses 2000 characters. The user is operating on macOS Sonoma with Python 3.11 and the latest versions of crewAI and crewAI Tools within a virtual environment. A possible solution is referenced in issue #3390.*

## üöÄ Pull Requests
- Opened a [PR](https://github.com/crewAIInc/crewAI/pull/3390) in [crewAIInc/crewAI]: Adding user_interaction and agent_interaction directly from messages (2025-08-23).
  > *AI Summary: @Vidit-Ostwal has suggested significant changes in the current PR. Instead of incorporating user_message and agent_message in the metadata, these should now be included directly in the message during the save method invocation of Mem0 Storage. Additionally, the messages parameter has been removed from the metadata configuration due to its constraint of 2000 characters. These modifications aim to streamline the process and ensure more effective data handling within the storage system, enhancing functionality and usability.*

## ‚≠ê Starred Repositories
- Starred [openai/baselines](https://github.com/openai/baselines) on 2025-08-28.
- Starred [willccbb/verifiers](https://github.com/willccbb/verifiers) on 2025-08-24.
- Starred [ByteDance-Seed/seed-oss](https://github.com/ByteDance-Seed/seed-oss) on 2025-08-22.

## üç¥ Forked Repositories
- Forked [github/github-mcp-server](https://github.com/Vidit-Ostwal/github-mcp-server) on 2025-08-24.
- Forked [google-gemini/gemini-cli](https://github.com/Vidit-Ostwal/gemini-cli) on 2025-08-23.
