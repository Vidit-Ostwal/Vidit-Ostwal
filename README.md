# Recent GitHub Activity for Vidit-Ostwal

## üìù Recent Blogs
- [Training the Tokenizer](https://www.notion.so/207e478805d48090b34fcc5c8e8c3c01?v=207e478805d480cfac6c000ca3c80482) - *03-06-2025*
## üí¨ Recent Comments
- [Commented](https://github.com/huggingface/smolagents/issues/1385#issuecomment-2940933716) in [huggingface/smolagents] on 2025-06-04.
  > *AI Summary: @Vidit-Ostwal has suggested implementing a summarization process after a certain number of steps or tokens, specifically proposing that summarization should occur when 75% of the tokens are reached instead of waiting for the full 100%. This approach aims to enhance the efficiency of the summarization feature by allowing for timely insights rather than delaying until the completion of the entire process. Feedback on this suggestion is welcomed to refine the method further.*
- [Commented](https://github.com/crewAIInc/crewAI/issues/2945#issuecomment-2940886337) in [crewAIInc/crewAI] on 2025-06-04.
  > *AI Summary: @Vidit-Ostwal has suggested using version 0.121.1 in Jupyter Notebook for a project involving content creation about "Artificial Intelligence." The proposed structure involves three agents: a Content Planner, a Content Writer, and an Editor, each with specific roles and tasks. The Content Planner outlines strategic content, the Content Writer produces a blog post, and the Editor ensures quality and alignment with journalistic standards. Additionally, the suggestion includes leveraging Python files for inference to enhance functionality and maintain organization within the project workflow.*
- [Commented](https://github.com/huggingface/smolagents/issues/1385#issuecomment-2940857328) in [huggingface/smolagents] on 2025-06-04.
  > *AI Summary: @Vidit-Ostwal has suggested that Smolagent's codebase is a valuable learning resource for AI agents. While using it to build a knowledge bot that connects with company tools and APIs, the agent sometimes diverges by calling irrelevant API endpoints, maintaining outdated messages in the context window. This not only increases costs but may compromise performance. To address this, a solution for optimizing memory messages by removing or compressing old messages is desired, along with summarizing messages when reaching the context window limit.*
- [Commented](https://github.com/crewAIInc/crewAI/issues/2945#issuecomment-2940843595) in [crewAIInc/crewAI] on 2025-06-04.
  > *AI Summary: @Vidit-Ostwal has suggested addressing an issue where a task appears to be repeating multiple times, leading to a recursion error with a specific SSL certificate verification problem. The task involves prioritizing trends in Artificial Intelligence, identifying target audiences, and developing a content outline with SEO keywords and relevant data. To resolve the issue, it is recommended to upgrade the crewai version or utilize .py files for inference to avoid the recursion depth error and SSL connection problems.*
- [Commented](https://github.com/crewAIInc/crewAI/issues/2693#issuecomment-2940341329) in [crewAIInc/crewAI] on 2025-06-04.
  > *AI Summary: @Vidit-Ostwal has suggested that when interacting with litellm, rather than sending tools directly, it‚Äôs more effective to provide tools in the description of the entire message. This method has been observed to avoid issues where the llm incorrectly generates description keys. As the format of tool definitions is evolving, there may be a need to reconsider the inclusion of descriptions or the representation of arguments, given that the current approach does not explicitly send tool arguments as shown in typical examples.*

## üêõ Issues Raised
No issues raised recently.

## üöÄ Pull Requests
- Opened a [PR](https://github.com/ariG23498/gemma3-object-detection/pull/29) in [ariG23498/gemma3-object-detection]: Added get_tokenizer_with_new_tokens_func (2025-06-02).
  > *AI Summary: @Vidit-Ostwal has suggested implementing a dynamic function that directly takes a configuration file as input. This function's purpose is to add tokens to the tokenizer efficiently. By allowing the configuration to be handled in this manner, the process becomes more streamlined and adaptable to various needs. This enhancement aims to improve the functionality and usability of the tokenizer by ensuring it can accommodate diverse configurations seamlessly while maintaining its core operation.*

## ‚≠ê Starred Repositories
- Starred [tokenbender/avataRL](https://github.com/tokenbender/avataRL) on 2025-06-01.

## üç¥ Forked Repositories
No repositories forked recently.
